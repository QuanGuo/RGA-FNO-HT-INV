{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"lkrxvz-gtM3I"},"source":["# Import and Mount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfwSWbvS_IN0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable, grad\n","from torch.optim.lr_scheduler import StepLR, ExponentialLR\n","from torch.utils import data\n","from torch.distributions import MultivariateNormal\n","from torch.nn.utils import weight_norm\n","from torchvision import models\n","import torchvision.utils as vutils\n","\n","try:\n","    from torchinfo import summary\n","except ImportError:\n","    !pip install torchinfo\n","    from torchinfo import summary\n","\n","try:\n","    import mat73\n","except ImportError:\n","    !pip install mat73\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import sys\n","import os\n","import time\n","import math\n","from collections import defaultdict\n","from timeit import default_timer\n","import random\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","work_dir = './RGA-FNO-HT-INV'\n","\n","os.chdir(work_dir)\n","!pwd\n","\n","from plot_utils.plotslib import *\n","from FNO.utils import _get_act, add_padding2, remove_padding2\n","from FNO.utilities3 import UnitGaussianNormalizer, LpLoss\n","from FNO.basics import SpectralConv2d\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0psPKkUq_LEb"},"outputs":[],"source":["# Set random seed for reproducibility\n","manualSeed = 999\n","print(\"Random Seed: \", manualSeed)\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","torch.cuda.manual_seed(manualSeed)\n","\n","def try_gpu(i=0):\n","  \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n","  if torch.cuda.device_count() >= i + 1:\n","    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","    return torch.device(f'cuda:{i}')\n","  return torch.device('cpu')\n","\n","device0 = try_gpu()\n","print(device0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GcFuy-nQRKFr"},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5Pj7rYoOK-W"},"outputs":[],"source":["data_dir = work_dir + '/Data/'\n","\n","model_dir = work_dir + '/models/'\n","fig_dir = work_dir + '/figs/'\n","\n","try:\n","    os.makedirs(model_dir)\n","    os.makedirs(fig_dir)\n","except: Exception"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fo45OoRxc0aL"},"outputs":[],"source":["fname = \"Exponential_steady_state\"\n","fname = \"Exponential_steady_state\"\n","filename = data_dir + fname + \"_fields.npz\"\n","with np.load(filename) as npzfile:\n","    realizations = npzfile['realizations']\n","    alpha = npzfile['alpha']\n","    Z = npzfile['Z']\n","    Q = npzfile['Q'][0]\n","    pump_id_list = npzfile['pump_id_list']\n","    for k in ['lx', 'ly', 'sigma2']:\n","        if k in npzfile.keys(): print(k, npzfile[k])\n","filename = data_dir + fname + \"_heads.npy\"\n","all_heads = np.load(filename, mmap_mode='r')\n","print(Q)\n","print(pump_id_list)\n","print(alpha.shape)\n","print(Z.shape)\n","\n","print(realizations.shape)\n","print(all_heads.shape)\n","\n","NR=realizations.shape[0]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rTeQAmvpDP0y"},"source":["# Experimental Domain\n","## Unit, Zero-centered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za-81Rerbv0i"},"outputs":[],"source":["############### define domain with (0,0) at center ######\n","nx = ny = int(math.sqrt(all_heads.shape[1]))\n","dx_real = 5.0/(nx/64.0)\n","dt_real = 0.1\n","\n","Lox, Loy = 1, 1\n","dx, dy = Lox/nx, Loy/ny\n","\n","x = np.arange((-Lox/2+dx/2),(Lox/2),dx)\n","y = np.arange((-Lox/2+dx/2),(Lox/2),dy)\n","\n","Xm, Ym = np.meshgrid(x,y)\n","\n","X_star = np.hstack((Xm.flatten()[:,None], Ym.flatten()[:,None]))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QUBMi7mlwkgW"},"source":["# Fourier Neural Operator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJZtacd37U6q"},"outputs":[],"source":["class FNO2d(nn.Module):\n","    def __init__(self, modes1, modes2,\n","                 width=64, fc_dim=128,\n","                 layers=None,\n","                 in_dim=3, out_dim=1,\n","                 act='gelu',\n","                 pad_ratio=[0., 0.]):\n","        super(FNO2d, self).__init__()\n","        if isinstance(pad_ratio, float):\n","            pad_ratio = [pad_ratio, pad_ratio]\n","        else:\n","            assert len(pad_ratio) == 2, 'Cannot add padding in more than 2 directions'\n","        self.modes1 = modes1\n","        self.modes2 = modes2\n","\n","        self.pad_ratio = pad_ratio\n","        if layers is None:\n","            self.layers = [width] * (len(modes1) + 1)\n","        else:\n","            self.layers = layers\n","        self.fc0 = nn.Linear(in_dim, layers[0])\n","\n","        self.sp_convs = nn.ModuleList([SpectralConv2d(\n","            in_size, out_size, mode1_num, mode2_num)\n","            for in_size, out_size, mode1_num, mode2_num\n","            in zip(self.layers, self.layers[1:], self.modes1, self.modes2)])\n","\n","        self.ws = nn.ModuleList([nn.Conv1d(in_size, out_size, 1)\n","                                 for in_size, out_size in zip(self.layers, self.layers[1:])])\n","\n","        self.fc1 = nn.Linear(layers[-1], fc_dim)\n","        self.fc2 = nn.Linear(fc_dim, layers[-1])\n","        self.fc3 = nn.Linear(layers[-1], out_dim)\n","        self.act = _get_act(act)\n","\n","    def forward(self, x):\n","        size_1, size_2 = x.shape[1], x.shape[2]\n","        if max(self.pad_ratio) > 0:\n","            num_pad1 = [round(i * size_1) for i in self.pad_ratio]\n","            num_pad2 = [round(i * size_2) for i in self.pad_ratio]\n","        else:\n","            num_pad1 = num_pad2 = [0.]\n","\n","        length = len(self.ws)\n","        batchsize = x.shape[0]\n","        grid = self.get_grid(x.shape, x.device)\n","        x = torch.cat((x, grid), dim=-1)\n","        x = self.fc0(x)\n","        x = x.permute(0, 3, 1, 2)   # B, C, X, Y\n","        x = add_padding2(x, num_pad1, num_pad2)\n","        size_x, size_y = x.shape[-2], x.shape[-1]\n","\n","        for i, (speconv, w) in enumerate(zip(self.sp_convs, self.ws)):\n","            x1 = speconv(x)\n","            x2 = w(x.view(batchsize, self.layers[i], -1)).view(batchsize, self.layers[i+1], size_x, size_y)\n","            x = x1 + x2\n","            if i != length - 1:\n","                x = self.act(x)\n","        x = remove_padding2(x, num_pad1, num_pad2)\n","        x = x.permute(0, 2, 3, 1)\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.fc2(x)\n","        x = self.act(x)\n","        x = self.fc3(x)\n","        return x\n","\n","    def get_grid(self, shape, device):\n","        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n","        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n","        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n","        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n","        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n","        return torch.cat((gridx, gridy), dim=-1).to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5sEc7akBVLWR"},"source":["##FNO Forward Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hip0G94VFlJ_"},"outputs":[],"source":["config = defaultdict(dict)\n","config['model'] = {\n","    'modes1':[20]*4,\n","    'modes2':[20]*4,\n","    'fc_dim':128,\n","    'layers':[64]*5,\n","    'pad_ratio':[1,1],\n","    'out_dim':5,\n","    'act':'gelu'\n","}\n","FONet = FNO2d(\n","    modes1=config['model']['modes1'],\n","    modes2=config['model']['modes2'],\n","    fc_dim=config['model']['fc_dim'],\n","    layers=config['model']['layers'],\n","    pad_ratio=config['model']['pad_ratio'],\n","    out_dim=config['model']['out_dim'],\n","    act=config['model']['act']\n",").to(device0)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cc9EEQhuFQ26"},"source":["*load state variables from trained model*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zfpuShLcPvf"},"outputs":[],"source":["FONet.load_state_dict(torch.load(model_dir+fname+'_FNO_HT.pt', map_location=device0))\n","\n","for param in FONet.parameters():\n","  param.requires_grad = False\n","summary(FONet, (1,32,32,1))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"X515yqDsEfFd"},"source":["## RGA Decoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aF3f-u6KMuT"},"outputs":[],"source":["class FC_block(nn.Module):\n","  ''' encoder with CNN '''\n","  def __init__(self, in_feat, out_feat, params=None, normalize=False, act=nn.Tanh(), exp=True):\n","      super(FC_block, self).__init__()\n","      self.layer = [nn.Linear(in_feat, out_feat)]\n","      if params is not None:\n","          # Normalization occurs inside the model\n","          self.register_buffer('W', torch.tensor(params['Z'],dtype=torch.float32))\n","          self.register_buffer('b', torch.tensor(params['mu'],dtype=torch.float32))\n","          with torch.no_grad():\n","              self.layer[0].weight = nn.Parameter(self.W)\n","              self.layer[0].bias = nn.Parameter(self.b)\n","\n","      if normalize:\n","          self.layer.append(nn.BatchNorm1d(out_feat, 0.8))\n","      if act:\n","          self.layer.append(act)\n","\n","      self.module = nn.Sequential(*self.layer)\n","      self.exp = exp\n","  def forward(self, x):\n","      return self.module(x).exp() if self.exp else self.module(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADKqegCQNrTH"},"outputs":[],"source":["in_feat = 50\n","out_feat = nx*ny\n","params = {\n","    \"Z\":Z.T,\n","    \"mu\":np.zeros((1,))\n","}\n","KNet = FC_block(in_feat, out_feat, params,act=None,exp=True).to(device0)\n","for param in KNet.parameters():\n","    param.requires_grad = False\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tVLpKVqQGxCN"},"source":["# Training data\n","*sample & normalizaton*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC8uRiJEGjoo"},"outputs":[],"source":["heads = all_heads[:,:,-1,:].reshape((NR,nx,ny,-1))\n","\n","hmean = np.mean(heads,0)\n","hstd = np.std(heads,0)\n","\n","Kmean = np.mean(np.exp(realizations),0)\n","Kstd = np.std(np.exp(realizations),0)\n","\n","x_normalizer_recover = UnitGaussianNormalizer(torch.ones((0,))).to(device0)\n","x_normalizer_recover.mean = torch.tensor(Kmean[...],dtype=torch.float32)\n","x_normalizer_recover.std = torch.tensor(Kstd[...],dtype=torch.float32)\n","x_normalizer_recover.to(device0)\n","y_normalizer_recover = UnitGaussianNormalizer(torch.ones((0,)))\n","y_normalizer_recover.mean = torch.tensor(hmean[...],dtype=torch.float32)\n","y_normalizer_recover.std = torch.tensor(hstd[...],dtype=torch.float32)\n","y_normalizer_recover.to(device0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EYxhN13NFYjy"},"source":["*forward propagation and results of RGA-FNO*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPP0X-nU9RCs"},"outputs":[],"source":["shift = 10\n","inputs=torch.tensor(alpha[shift:shift+5,:],dtype=torch.float32,device=device0)\n","x_recover = KNet(inputs).view(-1,nx,ny).permute(0,2,1).to(device0)\n","\n","x_recover = x_normalizer_recover.encode(x_recover)\n","\n","outs = FONet(x_recover.unsqueeze(-1)).squeeze(-1)\n","\n","outs = y_normalizer_recover.decode(outs)\n","\n","ys = torch.tensor(heads[shift:shift+5,...], dtype=torch.float32)\n","\n","preds = outs[...].detach().cpu().numpy()\n","refs = ys[...].detach().cpu().numpy()\n","fig = plot_forward_operator(realizations[shift:shift+10,...], preds[...,0], refs[...,0], cmaplnK='jet')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5-RPddr6XpUM"},"source":["## Reference Data\n","1. measure HT data\n","2. add noise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8HUUB8sxnYX"},"outputs":[],"source":["#################  well network cell id ##################\n","print(int(nx/8))\n","xloc = np.arange(int(nx/4),int(nx*3/4+1),int(nx/8))\n","yloc = np.arange(int(ny/4),int(ny*3/4+1),int(ny/8))\n","\n","xloc = np.tile(xloc,5)\n","yloc = np.repeat(yloc,5)\n","\n","pump_id_list = [0,4,12,20,24]\n","pump_well_index = [xloc[pump_id_list], yloc[pump_id_list],[]]\n","print(pump_well_index)\n","\n","dtb = int(195 / (1024/nx))\n","Hnum = 6\n","xloc = np.linspace(0+dtb,nx-dtb,Hnum ,dtype=int)\n","yloc = np.linspace(0+dtb,ny-dtb,Hnum ,dtype=int)\n","xloc = np.tile(xloc,Hnum)\n","yloc = np.repeat(yloc,Hnum)\n","\n","HT_mask = torch.zeros(nx,ny,dtype=torch.bool)\n","HT_mask[xloc,yloc] = 1\n","\n","HT_mask = HT_mask.unsqueeze(-1).repeat(1,1,1)\n","\n","fid = 3\n","\n","ytrue = torch.tensor(heads[fid,...],requires_grad=True, dtype=torch.float32)\n","ytrue_masked_real = torch.masked_select(ytrue,HT_mask)\n","\n","ytrue_masked = ytrue_masked_real + torch.normal(mean=0.0,std=0.01*ytrue_masked_real.abs())\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ebww8J-oGcpg"},"source":["## Validation Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vvn5XN1qF8fE"},"outputs":[],"source":["dtb = int(50 / (1024/nx))\n","Knum = 6\n","xlin = np.linspace(0+dtb,nx-dtb,Knum ,dtype=int)\n","ylin = np.linspace(0+dtb,ny-dtb,Knum ,dtype=int)\n","xlin = np.tile(xlin,Knum)\n","ylin = np.repeat(ylin,Knum)\n","\n","Ktrue = torch.tensor(np.exp(realizations[fid:fid+1]),dtype=torch.float32, device=device0)\n","\n","K_mask = torch.zeros(1,nx,ny,dtype=torch.bool)\n","K_mask[0,xlin,ylin] = 1\n","K_masked = torch.masked_select(Ktrue,K_mask)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5OyK-VGmanEG"},"source":["# Optimization"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"f5GKqvbQGqUD"},"source":["## Initial Guess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WJgybKl1iq-"},"outputs":[],"source":["loc = torch.zeros((50,),dtype=torch.float32,requires_grad=True)\n","var = torch.ones((50,),dtype=torch.float32,requires_grad=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DkkVC48PFq1f"},"source":["## Optimization Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLupRT7LFsDI"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qadaaVBqbxd-"},"outputs":[],"source":["batch_size=1\n","relu_layer = torch.nn.ReLU()\n","num_epoch = 5\n","p_intervals = 1\n","\n","loss_func = nn.MSELoss()\n","\n","optimizer = torch.optim.SGD(\n","    [{'params': [var], 'lr':1e1, 'weight_decay':0 },\n","      {'params': [loc], 'lr':1e1, 'weight_decay':0 }],\n","    lr=1e-2,\n","    momentum=0.9\n",")\n","scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1, last_epoch=-1)\n","\n","start_time = time.time()\n","for epoch in range(num_epoch):\n","    loss = 0.0\n","    optimizer.zero_grad()\n","\n","    alpha_dist = torch.distributions.multivariate_normal.MultivariateNormal(loc, torch.diag(relu_layer(var)+1e-6))\n","    initial_guess_alpha = alpha_dist.rsample((100,)).mean(axis=0).requires_grad_(True)\n","\n","    Krecover = KNet(initial_guess_alpha.unsqueeze(0)).reshape(batch_size,nx,ny).permute(0,2,1)\n","    l1 = 1e0*loss_func(Krecover, Ktrue)\n","\n","    Krecover = x_normalizer_recover.encode(Krecover)\n","    out = FONet(Krecover.unsqueeze(-1)).squeeze(-1)\n","    out = y_normalizer_recover.decode(out)\n","    loss = 1e3*loss_func(torch.masked_select(out[0],HT_mask), ytrue_masked)\n","\n","    loss.backward(retain_graph=True)\n","\n","    optimizer.step()\n","    if epoch < 100:\n","        scheduler.step()\n","    if epoch%p_intervals==0 or epoch==num_epoch-1:\n","        elapsed = time.time() - start_time\n","        print(\"Epoch#: %d\" % epoch, end=\"\\t\")\n","        print(\"Loss1: %.4f\" % l1.item(), end=\"\\t\")\n","        print(\"Loss2: %.4f\" % loss.item(), end=\"\\t\")\n","        print(\"Time: %.4f\" % elapsed, end=\"\\t\")\n","        print(\"LR1: %f\" % optimizer.param_groups[0]['lr'], end=\"\\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jwIDu-ReEMvU"},"source":["## Save Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WISEOm9Vn0Ff"},"outputs":[],"source":["\n","# torch.save([loc, var], model_dir+\"/\" +fname+\"_\"+str(fid)+\"_loc_var_FNO.pt\")\n","\n","# loc, var = torch.load(model_dir+\"/\" +fname + \"_\"+str(fid)+\"_loc_var_FNO.pt\",map_location=device0)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IJrds32hQi1W"},"source":["# Plot all results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_MX_XTIQi1W"},"outputs":[],"source":["relu_layer = torch.nn.ReLU()\n","alpha_dist = torch.distributions.multivariate_normal.MultivariateNormal(loc, torch.diag(relu_layer(var)+1e-6))\n","\n","################### hydraulic conductivity colormap plot: 2D ##################\n","initial_guess_alpha = alpha_dist.rsample((100,)).detach().cpu().numpy()\n","\n","logK_preds = np.matmul(initial_guess_alpha,Z)\n","logK_pred = np.mean(np.matmul(loc.detach().cpu().numpy()[None,:]\\\n","                              ,Z),axis=0).reshape((nx,ny),order='F').flatten()\n","\n","logK_true = np.matmul(alpha[fid,:],Z).reshape((nx,ny),order='F').flatten()\n","\n","############################# metrics: accuracy with #############################\n","# threshold 10%\n","minlK, maxlK = np.min(logK_true), np.max(logK_true)\n","thres = 0.10\n","K_len = maxlK-minlK\n","\n","acc = abs(logK_true-logK_pred)/K_len\n","acc = sum(acc<thres)/(nx*ny)\n","print(acc)\n","\n","K_true = np.exp(logK_true).flatten()\n","K_pred = np.exp(logK_pred).flatten()\n","K_err = K_true - K_pred\n","error_K = np.linalg.norm(K_err,2)/np.linalg.norm(K_true,2)\n","print(error_K)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"24uULAUPIC4Z"},"source":["## Forward HT with Recovered Field"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBRUGNsJkJ71"},"outputs":[],"source":["x_recover = KNet(loc.unsqueeze(0)).view(-1,nx,ny).permute(0,2,1)\n","\n","x_recover = x_normalizer_recover.encode(x_recover)\n","outs = FONet(x_recover.unsqueeze(-1)).squeeze(-1)\n","outs = y_normalizer_recover.decode(outs)\n","\n","preds = outs.detach().cpu().numpy()\n","refs = ytrue.reshape(1,nx,ny,-1).detach().cpu().numpy()\n","\n","hmin, hmax = np.min(preds,axis=(1,2)), np.max(preds,axis=(1,2))\n","\n","hmin *= 0.95\n","hmax *= 1.05\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eseuYPrVIJbb"},"source":["## Hydraulic Heads"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abERgF_i4XBB"},"outputs":[],"source":["u_pred_plot = np.array([0])\n","u_true_plot = np.array([0])\n","u_pred_plot_list = []\n","u_true_plot_list = []\n","for i in range(5):\n","\n","    error_h = np.linalg.norm(refs[...,i].flatten()-preds[...,i].flatten(),2)/ \\\n","                    np.linalg.norm(refs[...,i].flatten(),2)\n","    print(error_h)\n","    upred_masked = torch.masked_select(outs[...,i],HT_mask[...]).detach().cpu().numpy()\n","    utrue_masked = torch.masked_select(ytrue[...,i],HT_mask[...]).detach().cpu().numpy()\n","    u_pred_plot = np.hstack((u_pred_plot, upred_masked))\n","    u_true_plot = np.hstack((u_true_plot, utrue_masked))\n","    u_pred_plot_list.append(upred_masked)\n","    u_true_plot_list.append(utrue_masked)\n","u_pred_plot = u_pred_plot[1:]\n","u_true_plot = u_true_plot[1:]\n","var_model = np.sum((u_pred_plot - u_true_plot)**2)\n","var_data = np.sum((u_true_plot-np.mean(u_true_plot))**2)\n","r2_inverse_head = (var_data-var_model) / var_data\n","print(r2_inverse_head)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0niq-y3wsb8h"},"outputs":[],"source":["#set font size\n","axis_label_font_size = 15\n","axis_tick_font_size = 15\n","legend_fontszie = 15\n","colorbar_font_size = 15\n","title_size = 15\n","contour_size = 10\n","\n","ti = 0\n","\n","iter = 0\n","\n","gridspec_kw=dict(wspace=0.55,hspace=0.5)\n","fig, axs = plt.subplots(3, 5,figsize=(25,13), gridspec_kw=gridspec_kw)\n","axs = axs.flatten()\n","\n","ax = axs[0]\n","im = ax.pcolormesh(Xm,Ym,logK_true.reshape((nx,ny)),cmap='jet')\n","im.set_clim(minlK, maxlK)\n","ax.set_title('(A1). True $lnT$', fontsize=title_size)\n","\n","ax = axs[1]\n","im = ax.pcolormesh(Xm,Ym,logK_pred.reshape((nx,ny)),cmap='jet')\n","im.set_clim(minlK, maxlK)\n","ax.set_title('(A2). Estimated $lnT$', fontsize=title_size)\n","\n","for ax in axs[:2]:\n","    # Divide existing axes and create new axes\n","    divider = make_axes_locatable(ax)\n","    cax = divider.append_axes(\"right\", size=\"8%\", pad=0.1)\n","\n","    cbar = fig.colorbar(\n","        im, cax=cax,ticks=[round(x,1) for x in\\\n","        np.arange(minlK*1.05, maxlK*1.05,(maxlK-minlK)/3)]\n","    )\n","    cbar.ax.tick_params(labelsize=colorbar_font_size)\n","\n","ax = axs[2]\n","logK_var = np.var(logK_preds,axis=0)\n","im = ax.pcolormesh(Xm,Ym,logK_var.reshape((nx,ny)),cmap='jet')\n","ax.set_title('(D). Variance Map',fontsize=title_size)\n","# Divide existing axes and create new axes\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"8%\", pad=0.1)\n","cbar = fig.colorbar(im, cax=cax)\n","cbar.ax.tick_params(labelsize=colorbar_font_size)\n","\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","ax = axs[3]\n","\n","im = ax.plot(np.arange(alpha[fid].shape[0]), alpha[fid], 'or', label='True')\n","im = ax.plot(\n","    np.arange(alpha[fid].shape[0]), loc.detach().cpu().numpy(),\n","    'b', label='Est'\n",")\n","ax.legend(\n","    loc='upper right',ncol=1,prop={'size': legend_fontszie}, framealpha=1,\n","    facecolor='none',borderpad=0.1,labelspacing=0.1,handletextpad=0.5,\n","    handlelength=0.2,columnspacing=0.01\n",")\n","ax.set_xlabel(\"index\",fontsize=axis_label_font_size)\n","ax.set_ylabel(r\"Latent variable $\\alpha$\",fontsize=axis_label_font_size)\n","\n","\n","ticks = [1, 10, 20, 30, 40, 50]\n","labels = [1, 10, 20, 30, 40, 50]\n","ax.set_xticks(ticks)\n","ax.set_xticklabels(labels,fontsize=axis_tick_font_size,ha='center')\n","ticks = [-3.0, -1.5, 0.0, 1.5, 3.0]\n","labels = ticks\n","ax.set_ylim([-3.5,3.5])\n","ax.set_yticks(ticks)\n","ax.set_yticklabels(labels,fontsize=axis_tick_font_size, ha='right', va='center')\n","ax.set_title('(E). true vs. estimates',fontsize=title_size)\n","\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","ax = axs[4]\n","min_u_true_plot, max_u_true_plot = min(u_true_plot), -0.01 #max(u_true_plot)\n","ax.plot([min_u_true_plot, max_u_true_plot], [min_u_true_plot, max_u_true_plot],color='k')\n","\n","for iii in range(5):\n","    ax.scatter(u_pred_plot_list[iii],u_true_plot_list[iii], label='p'+str(iii+1))\n","\n","ax.legend(\n","    loc='lower right',ncol=1,prop={'size': legend_fontszie}, framealpha=0,\\\n","    facecolor='none',borderpad=0.01,labelspacing=0.001,handletextpad=0.5, \\\n","    handlelength=0.2,columnspacing=0.02\n",")\n","ax.set_xlabel('predicted heads [m]',fontsize=axis_label_font_size)\n","ax.set_ylabel('true heads [m]',fontsize=axis_label_font_size)\n","\n","ticks = [-0.16, -0.10, -0.02]\n","labels = ticks #[18, 10, 2]\n","ax.set_xticks(ticks)\n","ax.set_yticks(ticks)\n","\n","ax.set_xticklabels(labels,fontsize=axis_tick_font_size,ha='center')\n","ax.set_yticklabels(labels,fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n","\n","ax.set_title('(F). data vs. prediction',fontsize=title_size)\n","\n","ax.text(\n","    -0.16, -0.05, '$R^2$=%.4f'%(r2_inverse_head), fontsize=15,\n","    bbox={'edgecolor':'w','facecolor':'w'}\n",")\n","\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","####################################################################################\n","\n","preds = outs[iter,...].detach().cpu().numpy()\n","refs = ys[iter,...].detach().cpu().numpy()\n","\n","hmin, hmax = np.min(preds,axis=(0,1)), np.max(preds,axis=(0,1))\n","\n","hmin *= 0.95\n","hmax *= 1.00\n","for iid in range(5,10):\n","\n","    ax = axs[iid]\n","    im = ax.pcolormesh(Xm, Ym, preds[...,iid-5], vmin=hmin[iid-5], vmax=hmax[iid-5])\n","\n","    ax.set_title('(B%d) FNO p%d' % (iid-4,iid-4), fontsize=title_size)\n","\n","\n","    ax = axs[iid+5]\n","    im = ax.pcolormesh(Xm, Ym, refs[...,iid-5],vmin=hmin[iid-5], vmax=hmax[iid-5])\n","\n","    ax.set_title('(C%d) True p%d' % (iid-4,iid-4), fontsize=title_size)\n","\n","    for ax in axs[[iid,iid+5]]:\n","        # Divide existing axes and create new axes\n","        divider = make_axes_locatable(ax)\n","        cax = divider.append_axes(\"right\", size=\"8%\", pad=0.1)\n","\n","        cbar = fig.colorbar(im, cax=cax,ticks=[round(x,1) for x in\\\n","                                              np.arange(hmin[iid-5],hmax[iid-5]*0.95,(hmax[iid-5]-hmin[iid-5])/4)])\n","        cbar.ax.tick_params(labelsize=colorbar_font_size)\n","\n","        lvls = np.linspace(hmin[iid-5], hmax[iid-5],7)\n","        CP = ax.contour(Xm, Ym, refs[...,iid-5],levels=lvls,cmap=\"coolwarm\")\n","        ax.clabel(CP,fontsize=contour_size,inline=True,inline_spacing=1,fmt='%.2f')\n","\n","\n","for ax in axs[np.delete(np.arange(15),[3,4])]:\n","    ######### x-axis name, ticks and labels #########\n","    ticks = [-0.5, 0.0, 0.5]\n","    labels = [0, 0.5, 1]\n","    ax.set_xlabel('x',fontsize=axis_label_font_size)\n","    ax.set_xticks(ticks)\n","    ax.set_xticklabels(labels,fontsize=axis_tick_font_size,ha='center')\n","\n","    ######### y-axis name, ticks and labels #########\n","    ax.set_ylabel('y',fontsize=axis_label_font_size)\n","    ax.set_yticks(ticks)\n","    ax.set_yticklabels(labels,fontsize=axis_tick_font_size,rotation=90, ha='right', va='center')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO/54THkfg1APvnv0V1z45R","machine_shape":"hm","private_outputs":true,"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
