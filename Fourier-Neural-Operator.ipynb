{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"2VdDmfl6NoHM"},"source":["## Import and Mount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lh65dF9BfbOC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable, grad\n","from torch.optim.lr_scheduler import StepLR, ExponentialLR\n","from torch.utils import data\n","from torch.distributions import MultivariateNormal\n","from torch.nn.utils import weight_norm\n","from torchvision import models\n","import torchvision.utils as vutils\n","\n","try:\n","    from torchinfo import summary\n","except ImportError:\n","    !pip install torchinfo\n","    from torchinfo import summary\n","\n","try:\n","    import mat73\n","except ImportError:\n","    !pip install mat73\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import sys\n","import os\n","import time\n","import math\n","from collections import defaultdict\n","from timeit import default_timer\n","import random\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","work_dir = './RGA-FNO-HT-INV'\n","\n","os.chdir(work_dir)\n","!pwd\n","\n","from plot_utils.plotslib import *\n","from FNO.utils import _get_act, add_padding2, remove_padding2\n","from FNO.utilities3 import UnitGaussianNormalizer, LpLoss\n","from FNO.basics import SpectralConv2d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODS0ErVrfj8S"},"outputs":[],"source":["# Set random seed for reproducibility\n","manualSeed = 999\n","print(\"Random Seed: \", manualSeed)\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)\n","torch.cuda.manual_seed(manualSeed)\n","\n","def try_gpu(i=0):\n","    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n","    if torch.cuda.device_count() >= i + 1:\n","        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","        return torch.device(f'cuda:{i}')\n","    return torch.device('cpu')\n","\n","device0 = try_gpu()\n","print(device0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GcFuy-nQRKFr"},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5Pj7rYoOK-W"},"outputs":[],"source":["data_dir = work_dir + '/Data/'\n","\n","model_dir = work_dir + '/models/'\n","fig_dir = work_dir + '/figs/'\n","\n","try:\n","    os.makedirs(model_dir)\n","    os.makedirs(fig_dir)\n","except: Exception"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fo45OoRxc0aL"},"outputs":[],"source":["fname = \"Exponential_steady_state\"\n","filename = data_dir + fname + \"_fields.npz\"\n","with np.load(filename) as npzfile:\n","    realizations = npzfile['realizations']\n","    alpha = npzfile['alpha']\n","    Z = npzfile['Z']\n","    Q = npzfile['Q'][0]\n","    pump_id_list = npzfile['pump_id_list']\n","    for k in ['lx', 'ly', 'sigma2']:\n","        if k in npzfile.keys(): print(k, npzfile[k])\n","filename = data_dir + fname + \"_heads.npy\"\n","all_heads = np.load(filename, mmap_mode='r')\n","print(Q)\n","print(pump_id_list)\n","print(alpha.shape)\n","print(Z.shape)\n","\n","print(realizations.shape)\n","print(all_heads.shape)\n","\n","NR=realizations.shape[0]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rTeQAmvpDP0y"},"source":["# Experimental Domain\n","## Unit, Zero-centered"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za-81Rerbv0i"},"outputs":[],"source":["############### define domain with (0,0) at center ######\n","nx = ny = int(math.sqrt(all_heads.shape[1]))\n","dx_real = 5.0/(nx/64.0)\n","dt_real = 0.1\n","\n","Lox, Loy = 1, 1\n","dx, dy = Lox/nx, Loy/ny\n","\n","x = np.arange((-Lox/2+dx/2),(Lox/2),dx)\n","y = np.arange((-Lox/2+dx/2),(Lox/2),dy)\n","\n","Xm, Ym = np.meshgrid(x,y)\n","\n","X_star = np.hstack((Xm.flatten()[:,None], Ym.flatten()[:,None]))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QUBMi7mlwkgW"},"source":["# Fourier Neural Operator class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NenvBWmEv4ib"},"outputs":[],"source":["class FNO2d(nn.Module):\n","    def __init__(self, modes1, modes2,\n","                 width=64, fc_dim=128,\n","                 layers=None,\n","                 in_dim=3, out_dim=1,\n","                 act='gelu',\n","                 pad_ratio=[0., 0.]):\n","        super(FNO2d, self).__init__()\n","        if isinstance(pad_ratio, float):\n","            pad_ratio = [pad_ratio, pad_ratio]\n","        else:\n","            assert len(pad_ratio) == 2, 'Cannot add padding in more than 2 directions'\n","        self.modes1 = modes1\n","        self.modes2 = modes2\n","\n","        self.pad_ratio = pad_ratio\n","        if layers is None:\n","            self.layers = [width] * (len(modes1) + 1)\n","        else:\n","            self.layers = layers\n","        self.fc0 = nn.Linear(in_dim, layers[0])\n","\n","        self.sp_convs = nn.ModuleList([SpectralConv2d(\n","            in_size, out_size, mode1_num, mode2_num)\n","            for in_size, out_size, mode1_num, mode2_num\n","            in zip(self.layers, self.layers[1:], self.modes1, self.modes2)])\n","\n","        self.ws = nn.ModuleList([nn.Conv1d(in_size, out_size, 1)\n","                                 for in_size, out_size in zip(self.layers, self.layers[1:])])\n","\n","        self.fc1 = nn.Linear(layers[-1], fc_dim)\n","        self.fc2 = nn.Linear(fc_dim, layers[-1])\n","        self.fc3 = nn.Linear(layers[-1], out_dim)\n","        self.act = _get_act(act)\n","\n","    def forward(self, x):\n","        size_1, size_2 = x.shape[1], x.shape[2]\n","        if max(self.pad_ratio) > 0:\n","            num_pad1 = [round(i * size_1) for i in self.pad_ratio]\n","            num_pad2 = [round(i * size_2) for i in self.pad_ratio]\n","        else:\n","            num_pad1 = num_pad2 = [0.]\n","\n","        length = len(self.ws)\n","        batchsize = x.shape[0]\n","        grid = self.get_grid(x.shape, x.device)\n","        x = torch.cat((x, grid), dim=-1)\n","        x = self.fc0(x)\n","        x = x.permute(0, 3, 1, 2)   # B, C, X, Y\n","        x = add_padding2(x, num_pad1, num_pad2)\n","        size_x, size_y = x.shape[-2], x.shape[-1]\n","\n","        for i, (speconv, w) in enumerate(zip(self.sp_convs, self.ws)):\n","            x1 = speconv(x)\n","            x2 = w(x.view(batchsize, self.layers[i], -1)).view(batchsize, self.layers[i+1], size_x, size_y)\n","            x = x1 + x2\n","            if i != length - 1:\n","                x = self.act(x)\n","        x = remove_padding2(x, num_pad1, num_pad2)\n","        x = x.permute(0, 2, 3, 1)\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.fc2(x)\n","        x = self.act(x)\n","        x = self.fc3(x)\n","        return x\n","\n","    def get_grid(self, shape, device):\n","        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n","        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n","        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n","        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n","        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n","        return torch.cat((gridx, gridy), dim=-1).to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4iLu4sT_RWqi"},"source":["# Training data\n","## sample\n","## normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC8uRiJEGjoo"},"outputs":[],"source":["heads = all_heads[:,:,-1,:].reshape((NR,nx,ny,-1))\n","hmean = np.mean(heads,0)\n","hstd = np.std(heads,0)\n","\n","Kmean = np.mean(np.exp(realizations),0)\n","Kstd = np.std(np.exp(realizations),0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_DUlI52Jefi"},"outputs":[],"source":["r = 2                     # spatial sampling steps\n","h = int(((nx - 1)/r) + 1) # sampled data resolution\n","\n","pid = [0,1,2,3,4]         # pumping well id\n","x_normalizer = UnitGaussianNormalizer(torch.ones((0,)))\n","x_normalizer.mean = torch.tensor(Kmean[::r,::r],dtype=torch.float32)\n","x_normalizer.std = torch.tensor(Kstd[::r,::r],dtype=torch.float32)\n","\n","y_normalizer = UnitGaussianNormalizer(torch.ones((0,)))\n","y_normalizer.mean = torch.tensor(hmean[::r,::r,pid],dtype=torch.float32).squeeze(-1)\n","y_normalizer.std = torch.tensor(hstd[::r,::r,pid],dtype=torch.float32).squeeze(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvYaoRgn3Qsk"},"outputs":[],"source":["ntrain = 500\n","ntest = 100\n","\n","################################################################\n","# load data and data normalization\n","################################################################\n","x_train = torch.tensor(np.exp(realizations[:ntrain,::r,::r]), dtype=torch.float32)\n","x_test = torch.tensor(np.exp(realizations[-ntest:,::r,::r]), dtype=torch.float32)\n","\n","y_train = torch.tensor(heads[:ntrain,...,pid][:,::r,::r], dtype=torch.float32).squeeze(-1)\n","y_test = torch.tensor(heads[-ntest:,...,pid][:,::r,::r], dtype=torch.float32).squeeze(-1)\n","\n","x_train = x_normalizer.encode(x_train)\n","x_test = x_normalizer.encode(x_test)\n","\n","y_train = y_normalizer.encode(y_train)\n","y_test = y_normalizer.encode(y_test)\n","\n","x_train = x_train.unsqueeze(-1)\n","x_test = x_test.unsqueeze(-1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vpEwUH49RQBC"},"source":["# FNO Model Init\n","## Configuration and Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJerLR1owoGN"},"outputs":[],"source":["config = defaultdict(dict)\n","config['model'] = {\n","    'modes1':[20]*4,\n","    'modes2':[20]*4,\n","    'fc_dim':128,\n","    'layers':[64]*5,\n","    'pad_ratio':[1,1],\n","    'out_dim':5,\n","    'act':'gelu'\n","}\n","model = FNO2d(\n","    modes1=config['model']['modes1'],\n","    modes2=config['model']['modes2'],\n","    fc_dim=config['model']['fc_dim'],\n","    layers=config['model']['layers'],\n","    pad_ratio=config['model']['pad_ratio'],\n","    out_dim=config['model']['out_dim'],\n","    act=config['model']['act']\n",").to(device0)\n","\n","summary(model, (1,32,32,1))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GTlJnknuRfFb"},"source":["# Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gWkk2HNwL9Y"},"outputs":[],"source":["batch_size = 10\n","learning_rate = 0.001\n","\n","# data loader\n","train_loader = torch.utils.data.DataLoader(\n","    torch.utils.data.TensorDataset(x_train, y_train), \\\n","    batch_size=batch_size,\\\n","    shuffle=True,\\\n","    generator=torch.Generator(device=device0)\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    torch.utils.data.TensorDataset(x_test, y_test),\\\n","    batch_size=batch_size,\\\n","    shuffle=False,\\\n","    generator=torch.Generator(device=device0)\n",")\n","\n","# optimizer and scheduler\n","epochs = 500\n","iterations = epochs*(ntrain//batch_size)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations)\n","\n","# loss function\n","myloss = LpLoss(size_average=False)\n","\n","for ep in range(epochs):\n","    #######################\n","    # training step\n","    #######################\n","    model.train()\n","    t1 = default_timer()\n","    train_l2 = 0\n","    for x, y in train_loader:\n","        x, y = x.to(device0), y.to(device0)\n","        # print(x.shape, y.shape)\n","        optimizer.zero_grad()\n","        out = model(x).squeeze(-1)\n","\n","        loss = myloss(out.reshape(batch_size,-1), y.reshape(batch_size,-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        train_l2 += loss.item()\n","\n","    #######################\n","    # validation loss\n","    #######################\n","    model.eval()\n","    test_l2 = 0.0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x, y = x.to(device0), y.to(device0)\n","            out = model(x).squeeze(-1)\n","            test_l2 += myloss(out.reshape(batch_size,-1), y.reshape(batch_size,-1)).item()\n","\n","    train_l2/= ntrain\n","    test_l2 /= ntest\n","\n","    t2 = default_timer()\n","\n","    print(\"Epoch#: %d\" % ep, end=\"\\t\")\n","    print(\"Time: %.4f\" % (t2-t1), end=\"\\t\")\n","    print(\"LR: %f\" % optimizer.param_groups[0]['lr'], end=\"\\t\")\n","    print(\"Loss:\", end=\" \")\n","    print(\"[Train %.4f]\" % (train_l2), end=\"\\t\")\n","    print(\"[Valid: %.4f]\" % (test_l2), end=\"\\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mQPOrsVERnaq"},"source":["# Trained Model Evaluation"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JpJJmkWOHwO2"},"source":["## Evaluate on finer resolution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OatamyxWDekk"},"outputs":[],"source":["x_normalizer_recover = UnitGaussianNormalizer(torch.ones((0,)))\n","x_normalizer_recover.mean = torch.tensor(Kmean[...],dtype=torch.float32)\n","x_normalizer_recover.std = torch.tensor(Kstd[...],dtype=torch.float32)\n","\n","y_normalizer_recover = UnitGaussianNormalizer(torch.ones((0,)))\n","y_normalizer_recover.mean = torch.tensor(hmean[...,pid],dtype=torch.float32).squeeze(-1)\n","y_normalizer_recover.std = torch.tensor(hstd[...,pid],dtype=torch.float32).squeeze(-1)\n","\n","# Selection 10 unseen realizations\n","shift = 550\n","x_recover = torch.tensor(np.exp(realizations[shift:shift+10,...]),dtype=torch.float32)\n","ys = torch.tensor(heads[shift:shift+10,:,:,pid], dtype=torch.float32).squeeze(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAE-LmpkSU6l"},"outputs":[],"source":["model.eval()\n","\n","with torch.no_grad():\n","    outs = model(x_normalizer_recover.encode(x_recover).unsqueeze(-1))\n","    outs = y_normalizer_recover.decode(outs)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zbYyZxQiILnI"},"source":["## Plot Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlDL6bZ5bCUs"},"outputs":[],"source":["preds = outs[...].detach().cpu().numpy()\n","refs = ys[...].detach().cpu().numpy()\n","fig = plot_forward_operator(realizations[shift:shift+10,...], preds[...,0], refs[...,0], cmaplnK='jet')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s3AwsqfSSXMh"},"source":["# Save Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSjGjZsFSIDC"},"outputs":[],"source":["# torch.save(model.state_dict(), model_dir+fname+'_FNO_HT.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFCI0LugSWpZ"},"outputs":[],"source":["# fname = \"Exponential_steady_state\"\n","# print(fname+'_FNO_HT.pth')\n","# model.load_state_dict(torch.load(model_dir+fname+'_FNO_HT.pt', map_location=device0))\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPvobbbqCo2AH42ar9Nc9+S","private_outputs":true,"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
